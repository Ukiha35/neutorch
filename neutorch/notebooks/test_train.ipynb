{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use TorchIO for your research, please cite the following paper:\n",
      "Pérez-García et al., TorchIO: a Python library for efficient loading,\n",
      "preprocessing, augmentation and patch-based sampling of medical images\n",
      "in deep learning. Credits instructions: https://torchio.readthedocs.io/#credits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import click\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from neutorch.model.IsoRSUNet import UNetModel\n",
    "from neutorch.model.io import save_chkpt, log_tensor\n",
    "from neutorch.model.loss import BinomialCrossEntropyWithLogits\n",
    "from neutorch.dataset.affinity import Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data'\n",
    "patch_size = (6,64,64)\n",
    "length = 200000\n",
    "dataset = Dataset(path, patch_size=patch_size, length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 64, 64) (13, 6, 64, 64)\n",
      "(1, 6, 64, 64) (13, 6, 64, 64)\n",
      "(1, 6, 64, 64) (13, 6, 64, 64)\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    x, y = dataset[i]\n",
    "    print(x.shape,y.shape)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from einops import rearrange\n",
    "\n",
    "def merge(x):\n",
    "\n",
    "        B, D, H, W, C = x.shape\n",
    "\n",
    "        x0 = x[:, :, 0::2, 0::2, :]  # B D H/2 W/2 C\n",
    "        x1 = x[:, :, 1::2, 0::2, :]  # B D H/2 W/2 C\n",
    "        x2 = x[:, :, 0::2, 1::2, :]  # B D H/2 W/2 C\n",
    "        x3 = x[:, :, 1::2, 1::2, :]  # B D H/2 W/2 C\n",
    "        x = torch.cat([x0, x1, x2, x3], -1)  # B D H/2 W/2 4*C\n",
    "\n",
    "\n",
    "        # reduce\n",
    "        x = x[:,:,:,:,:C*2]\n",
    "\n",
    "        return x\n",
    "\n",
    "      \n",
    "def expand(x):\n",
    "        B, D, H, W, C = x.shape\n",
    "\n",
    "        # expansion(x)  # B L 2C\n",
    "        x = torch.cat([x,x],-1)\n",
    "\n",
    "\n",
    "        # c = 2*C//4\n",
    "        # # get mutliple pixel repesentation from channels\n",
    "        # c0 = x[:, :, :, :, :c]       # B D H W 2C/4\n",
    "        # c1 = x[:, :, :, :, c:2*c]    # B D H W 2C/4\n",
    "        # c2 = x[:, :, :, :, 2*c:3*c]  # B D H W 2C/4\n",
    "        # c3 = x[:, :, :, :, 3*c:]     # B D H W 2C/4\n",
    "\n",
    "        # # insert side by side into new array\n",
    "        # # maybe there is better way to do this that doesnt init new array\n",
    "        # device = x.get_device()\n",
    "        # if device < 0:\n",
    "        #     device = None\n",
    "        # new_x = torch.zeros(\n",
    "        #     (B, D, H*2, W*2, c), device=device)  # B 2H 2W C/2\n",
    "\n",
    "        # new_x[:, :, 0::2, 0::2, :] = c0\n",
    "        # new_x[:, :, 1::2, 0::2, :] = c1\n",
    "        # new_x[:, :, 0::2, 1::2, :] = c2\n",
    "        # new_x[:, :, 1::2, 1::2, :] = c3\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]]]) torch.Size([1, 1, 4, 4, 1])\n",
      "torch.Size([1, 1, 2, 2, 2])\n",
      "torch.Size([1, 1, 4, 4, 1])\n",
      "tensor([[[ 0.,  0.,  2.,  2.],\n",
      "         [ 4.,  4.,  6.,  6.],\n",
      "         [ 8.,  8., 10., 10.],\n",
      "         [12., 12., 14., 14.]]]) torch.Size([1, 1, 4, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "D = 1\n",
    "H = 4\n",
    "W = 4\n",
    "C = 1\n",
    "B = 1\n",
    "input = torch.arange(0,D*H*W*C*B)\n",
    "input = torch.reshape(input,(B,D,H,W,C))\n",
    "print(input[0,:,:,:,0], input.shape)\n",
    "\n",
    "merged = merge(input)\n",
    "print(merged.shape)\n",
    "expanded = expand(merged)\n",
    "print(expanded.shape)\n",
    "\n",
    "print(expanded[0,:,:,:,0], expanded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]]]) torch.Size([1, 1, 4, 4, 1])\n",
      "torch.Size([1, 1, 2, 2, 2])\n",
      "torch.Size([1, 1, 4, 4, 1])\n",
      "tensor([[[ 0,  4,  2,  6],\n",
      "         [ 0,  4,  2,  6],\n",
      "         [ 8, 12, 10, 14],\n",
      "         [ 8, 12, 10, 14]]]) torch.Size([1, 1, 4, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "D = 1\n",
    "H = 4\n",
    "W = 4\n",
    "C = 1\n",
    "B = 1\n",
    "input = torch.arange(0,D*H*W*C*B)\n",
    "input = torch.reshape(input,(B,D,H,W,C))\n",
    "print(input[0,:,:,:,0], input.shape)\n",
    "\n",
    "merged = merge(input)\n",
    "print(merged.shape)\n",
    "expanded = expand(merged)\n",
    "print(expanded.shape)\n",
    "\n",
    "print(expanded[0,:,:,:,0], expanded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "torch.Size([2, 4, 4])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zz = torch.zeros((4,4,2))\n",
    "zz[:,:,0] = torch.reshape(torch.arange(0,16),(4,4))\n",
    "zz[:,:,1] = torch.reshape(torch.arange(0,16),(4,4))\n",
    "print(zz[:,:,1])\n",
    "print(zz[:,:,0])\n",
    "zz = torch.moveaxis(zz, -1, 0)\n",
    "print(zz.shape)\n",
    "print(zz[0,:,:])\n",
    "print(zz[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2., 3.],\n",
      "        [0., 1., 2., 3.]])\n",
      "tensor([[4., 5., 6., 7.],\n",
      "        [4., 5., 6., 7.]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}