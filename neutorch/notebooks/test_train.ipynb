{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use TorchIO for your research, please cite the following paper:\n",
      "Pérez-García et al., TorchIO: a Python library for efficient loading,\n",
      "preprocessing, augmentation and patch-based sampling of medical images\n",
      "in deep learning. Credits instructions: https://torchio.readthedocs.io/#credits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import click\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from neutorch.model.IsoRSUNet import UNetModel\n",
    "from neutorch.model.io import save_chkpt, log_tensor\n",
    "from neutorch.model.loss import BinomialCrossEntropyWithLogits\n",
    "from neutorch.dataset.affinity import Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data'\n",
    "patch_size = (6,64,64)\n",
    "length = 200000\n",
    "dataset = Dataset(path, patch_size=patch_size, length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 64, 64) (13, 6, 64, 64)\n",
      "(1, 6, 64, 64) (13, 6, 64, 64)\n",
      "(1, 6, 64, 64) (13, 6, 64, 64)\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    x, y = dataset[i]\n",
    "    print(x.shape,y.shape)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def merge(x,H,W):\n",
    "\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n",
    "        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n",
    "\n",
    "        # reduce\n",
    "        x = x[:,:,:C*2]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def expand(x, H, W):\n",
    "        B, L, C = x.shape\n",
    "        # expansion(x)  # B L 2C\n",
    "        x = torch.cat([x,x],-1)\n",
    "\n",
    "        x = x.view(B, H, W, C*2)  # B H W 2C\n",
    "\n",
    "        # padding\n",
    "        pad_input = (H % 2 == 1) or (W % 2 == 1)\n",
    "        if pad_input:\n",
    "            x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))\n",
    "\n",
    "        c = 2*C//4\n",
    "        # get mutliple pixel repesentation from channels\n",
    "        c0 = x[:, :, :, :c]  # B H W 2C/4\n",
    "        c1 = x[:, :, :, c:2*c]  # B H W 2C/4\n",
    "        c2 = x[:, :, :, 2*c:3*c]  # B H W 2C/4\n",
    "        c3 = x[:, :, :, 3*c:]  # B H W 2C/4\n",
    "\n",
    "        # # insert side by side into new array\n",
    "        new_x = torch.zeros((B, H*2, W*2, c))  # B 2H 2W C/2\n",
    "\n",
    "        new_x[:, 0::2, 0::2, :] = c0\n",
    "        new_x[:, 1::2, 0::2, :] = c1\n",
    "        new_x[:, 0::2, 1::2, :] = c2\n",
    "        new_x[:, 1::2, 1::2, :] = c3\n",
    "\n",
    "        x = x.view(B, -1, C//2)  # B L C/2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]]) torch.Size([1, 4, 4, 1])\n",
      "torch.Size([1, 4, 2])\n",
      "tensor([ 0,  2,  8, 10])\n",
      "tensor([ 4,  6, 12, 14])\n",
      "torch.Size([1, 8, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 4, 4, 1]' is invalid for input of size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7030fa462998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mexpanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mexpanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 4, 4, 1]' is invalid for input of size 8"
     ]
    }
   ],
   "source": [
    "H = 4\n",
    "W = 4\n",
    "C = 1\n",
    "B = 1\n",
    "input = torch.arange(0,H*W*C*B)\n",
    "input = torch.reshape(input,(B,H,W,C))\n",
    "print(input[0,:,:,0], input.shape)\n",
    "input = input.view(C,-1,B)\n",
    "merged = merge(input,H,W)\n",
    "\n",
    "print(merged.shape)\n",
    "print(merged[0,:,0])\n",
    "print(merged[0,:,1])\n",
    "\n",
    "expanded = expand(merged,2,2)\n",
    "print(expanded.shape)\n",
    "expanded = expanded.view(C,H,W,B)\n",
    "print(expanded[0,:,:,0], expanded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "torch.Size([2, 4, 4])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zz = torch.zeros((4,4,2))\n",
    "zz[:,:,0] = torch.reshape(torch.arange(0,16),(4,4))\n",
    "zz[:,:,1] = torch.reshape(torch.arange(0,16),(4,4))\n",
    "print(zz[:,:,1])\n",
    "print(zz[:,:,0])\n",
    "zz = torch.moveaxis(zz, -1, 0)\n",
    "print(zz.shape)\n",
    "print(zz[0,:,:])\n",
    "print(zz[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2., 3.],\n",
      "        [0., 1., 2., 3.]])\n",
      "tensor([[4., 5., 6., 7.],\n",
      "        [4., 5., 6., 7.]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}